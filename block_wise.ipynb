{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resnet import *\n",
    "from models.vgg import *\n",
    "from models.mobilenetv2 import qmobilenetv2\n",
    "from models.mobilenet import qmobilenet\n",
    "from quantize_utils import *\n",
    "from utils import *\n",
    "import conf\n",
    "dataloader = cifar100DataLoader(train=True, shuffle=True, batch_size=128, normalized=True)\n",
    "# dataloader = cifar10DataLoader(train=True, normalized=False, batch_size=128, shuffle=True)\n",
    "sampels, label = iter(dataloader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader = cifar100DataLoader(train=True, shuffle=True, batch_size=128, normalized=True)\n",
    "dataloader = cifar10DataLoader(train=True, normalized=False, batch_size=128, shuffle=True)\n",
    "sampels, label = iter(dataloader).next()\n",
    "model = getCifar10Model('vgg11', pretrained=True)\n",
    "model.eval()\n",
    "model.cpu()\n",
    "sampels = sampels.to('cpu')\n",
    "IR = [sampels]\n",
    "idx = []\n",
    "with torch.no_grad():\n",
    "    for i in range(29):\n",
    "        IR.append(model.features[i](IR[-1]))\n",
    "        if type(model.features[i]) in [torch.nn.Conv2d, QConv2d]:\n",
    "            idx.append(i)\n",
    "IR = [IR[i] for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg19_bn()\n",
    "load_qnet(model, conf.vgg19_path)\n",
    "model.eval()\n",
    "model.cpu()\n",
    "sampels = sampels.to('cpu')\n",
    "IR = [sampels]\n",
    "idx = []\n",
    "with torch.no_grad():\n",
    "    for i in range(53):\n",
    "        IR.append(model.features[i](IR[-1]))\n",
    "        if type(model.features[i]) == torch.nn.Conv2d:\n",
    "            idx.append(i)\n",
    "IR = [IR[i] for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "res18 = qresnet18()\n",
    "load_qnet(res18, conf.resnet18_path)\n",
    "# mixed_quantize_with_partition(res18, [2] * (lenQmodel(res18)-1), split=lenQmodel(res18)-1, a_bit=8)\n",
    "res18.eval()\n",
    "res18.cpu()\n",
    "sampels = sampels.to('cpu')\n",
    "IR = []\n",
    "IR.append(res18.conv1(sampels))\n",
    "IR.append(res18.conv2_x[0](IR[-1]))\n",
    "IR.append(res18.conv2_x[1](IR[-1]))\n",
    "IR.append(res18.conv3_x[0](IR[-1]))\n",
    "IR.append(res18.conv3_x[1](IR[-1]))\n",
    "IR.append(res18.conv4_x[0](IR[-1]))\n",
    "IR.append(res18.conv4_x[1](IR[-1]))\n",
    "IR.append(res18.conv5_x[0](IR[-1]))\n",
    "IR.append(res18.conv5_x[1](IR[-1]))\n",
    "x = res18.avg_pool(IR[-1])\n",
    "y = res18.fc(x.view(x.size(0), -1))\n",
    "_, pred = y.topk(5, 1, largest=True, sorted=True)\n",
    "label = label.view(label.size(0), -1).expand_as(pred)\n",
    "correct = pred.eq(label).float()\n",
    "print(correct[:, :1].sum() / y.shape[0])\n",
    "IR.insert(0, res18.conv1[0](sampels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampels = sampels.to('cpu')\n",
    "IR_e = []\n",
    "for i in range(lenQmodel(res18, [BasicBlock])):\n",
    "    next_block_idx = bw_split(res18, [BasicBlock, BottleNeck], i)\n",
    "    res18(sampels)\n",
    "    IR_e.append(extract_IR(res18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res50 = qresnet50()\n",
    "load_qnet(res50, conf.resnet50_path)\n",
    "# test(res50, dataloader, 'cuda:1')\n",
    "res50.eval()\n",
    "res50.cpu()\n",
    "sampels = sampels.to('cpu')\n",
    "IR = []\n",
    "IR.append(res50.conv1(sampels))\n",
    "IR.append(res50.conv2_x[0](IR[-1]))\n",
    "IR.append(res50.conv2_x[1](IR[-1]))\n",
    "IR.append(res50.conv2_x[2](IR[-1]))\n",
    "IR.append(res50.conv3_x[0](IR[-1]))\n",
    "IR.append(res50.conv3_x[1](IR[-1]))\n",
    "IR.append(res50.conv3_x[2](IR[-1]))\n",
    "IR.append(res50.conv3_x[3](IR[-1]))\n",
    "IR.append(res50.conv4_x[0](IR[-1]))\n",
    "IR.append(res50.conv4_x[1](IR[-1]))\n",
    "IR.append(res50.conv4_x[2](IR[-1]))\n",
    "IR.append(res50.conv4_x[3](IR[-1]))\n",
    "IR.append(res50.conv4_x[4](IR[-1]))\n",
    "IR.append(res50.conv4_x[5](IR[-1]))\n",
    "IR.append(res50.conv5_x[0](IR[-1]))\n",
    "IR.append(res50.conv5_x[1](IR[-1]))\n",
    "IR.append(res50.conv5_x[2](IR[-1]))\n",
    "x = res50.avg_pool(IR[-1])\n",
    "y = res50.fc(x.view(x.size(0), -1))\n",
    "_, pred = y.topk(5, 1, largest=True, sorted=True)\n",
    "label = label.view(label.size(0), -1).expand_as(pred)\n",
    "correct = pred.eq(label).float()\n",
    "print(correct[:, :1].sum() / y.shape[0])\n",
    "IR.insert(0, res50.conv1[0](sampels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov = qmobilenet()\n",
    "load_qnet(mov, conf.mobilenet_path)\n",
    "# mixed_quantize_with_partition(mov, [6] * (lenQmodel(mov)-1), split=lenQmodel(mov)-1, a_bit=8)\n",
    "mov.eval()\n",
    "mov.cpu()\n",
    "sampels = sampels.to('cpu')\n",
    "IR = []\n",
    "IR.append(mov.stem[0](sampels))\n",
    "IR.append(mov.stem[1](IR[-1]))\n",
    "IR.append(mov.conv1[0](IR[-1]))\n",
    "IR.append(mov.conv1[1](IR[-1]))\n",
    "IR.append(mov.conv2[0](IR[-1]))\n",
    "IR.append(mov.conv2[1](IR[-1]))\n",
    "IR.append(mov.conv3[0](IR[-1]))\n",
    "IR.append(mov.conv3[1](IR[-1]))\n",
    "IR.append(mov.conv3[2](IR[-1]))\n",
    "IR.append(mov.conv3[3](IR[-1]))\n",
    "IR.append(mov.conv3[4](IR[-1]))\n",
    "IR.append(mov.conv3[5](IR[-1]))\n",
    "IR.append(mov.conv4[0](IR[-1]))\n",
    "IR.append(mov.conv4[1](IR[-1]))\n",
    "\n",
    "x = mov.avg(IR[-1])\n",
    "x = x.view(x.size(0), -1)\n",
    "y = mov.fc(x)\n",
    "_, pred = y.topk(5, 1, largest=True, sorted=True)\n",
    "label = label.view(label.size(0), -1).expand_as(pred)\n",
    "correct = pred.eq(label).float()\n",
    "print(correct[:, :1].sum() / y.shape[0])\n",
    "IR.insert(0, mov.stem[0].conv(sampels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov2 = qmobilenetv2()\n",
    "load_qnet(mov2, conf.mobilenetv2_path)\n",
    "mixed_quantize_with_partition(mov2, [8] * (lenQmodel(mov2)-1), split=53, a_bit=-1)\n",
    "mov2.eval()\n",
    "mov2.cpu()\n",
    "sampels = sampels.to('cpu')\n",
    "IR = []\n",
    "IR.append(mov2.pre(sampels))\n",
    "IR.append(mov2.stage1(IR[-1]))\n",
    "IR.append(mov2.stage2[0](IR[-1]))\n",
    "IR.append(mov2.stage2[1](IR[-1]))\n",
    "IR.append(mov2.stage3[0](IR[-1]))\n",
    "IR.append(mov2.stage3[1](IR[-1]))\n",
    "IR.append(mov2.stage3[2](IR[-1]))\n",
    "IR.append(mov2.stage4[0](IR[-1]))\n",
    "IR.append(mov2.stage4[1](IR[-1]))\n",
    "IR.append(mov2.stage4[2](IR[-1]))\n",
    "IR.append(mov2.stage4[3](IR[-1]))\n",
    "IR.append(mov2.stage5[0](IR[-1]))\n",
    "IR.append(mov2.stage5[1](IR[-1]))\n",
    "IR.append(mov2.stage5[2](IR[-1]))\n",
    "IR.append(mov2.stage6[0](IR[-1]))\n",
    "IR.append(mov2.stage6[1](IR[-1]))\n",
    "IR.append(mov2.stage6[2](IR[-1]))\n",
    "IR.append(mov2.stage7(IR[-1]))\n",
    "IR.append(mov2.conv1(IR[-1]))\n",
    "\n",
    "x = torch.nn.functional.adaptive_avg_pool2d(IR[-1], 1)\n",
    "x = mov2.conv2(x)\n",
    "y = x.view(x.size(0), -1)\n",
    "_, pred = y.topk(5, 1, largest=True, sorted=True)\n",
    "label = label.view(label.size(0), -1).expand_as(pred)\n",
    "correct = pred.eq(label).float()\n",
    "print(correct[:, :1].sum() / y.shape[0])\n",
    "IR.insert(0, mov2.pre[0](sampels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 , 0.22897884249687195\n",
      "1 , 0.8808073997497559\n",
      "2 , 0.8732382655143738\n",
      "3 , 0.8745739459991455\n",
      "4 , 0.8875979781150818\n",
      "5 , 0.8894134759902954\n",
      "6 , 0.9964187145233154\n",
      "7 , 1.0245037078857422\n",
      "8 , 1.0736452341079712\n",
      "9 , 1.1709766387939453\n"
     ]
    }
   ],
   "source": [
    "# model = mov\n",
    "with torch.no_grad():\n",
    "    for i, ir in enumerate(IR):\n",
    "        ir_images = ir2images(ir, (32, 32))\n",
    "        sampels = sampels.to('cuda:1')\n",
    "        # print(1 / maxSSIM(ir_images, sampels.to('cuda:1')))\n",
    "        # print(minKL(ir_images, sampels.to('cuda:1'), res18.to('cuda:1')))\n",
    "        print(i, ',', minMSE(ir_images, sampels, device='cuda').item())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d912fd5a214bdf4255a8a1783e88f12c1aa759a860b7ede2335e489e44772f26"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('py3.8.0-pytorch1.7.0': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
